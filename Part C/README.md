# Part C
Running llms on your local laptops https://github.com/ollama/ollama

1) download ollama and gemma 2b model with it and demonstrate it running on your laptop <br>
DEMO: https://drive.google.com/file/d/1n8GM5_5BXoaknF_tzCgEPleB7ajPa44F/view?usp=sharing  
2) download and run a multimodal with ollama and show case various capabilities

3) showcase rest api of ollama with exampels

4) run ollama in google colab - https://pub.towardsai.net/running-ollama-on-google-colab-free-tier-a-step-by-step-guide-9ef74b1f8f7a

5) use open webui https://github.com/open-webui/open-webui

and demonstrate various tasks of ollama the key featuers of openwebui
